{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Proyecto: Análisis de Comportamiento de Usuarios\n",
    "\n",
    "Este notebook realiza los siguientes pasos:\n",
    "\n",
    "1. Carga y exploración del dataset\n",
    "2. División en conjuntos de entrenamiento, validación y prueba\n",
    "3. Entrenamiento y ajuste de hiperparámetros de un modelo (Random Forest)\n",
    "4. Evaluación del modelo en el conjunto de validación y prueba\n",
    "5. Prueba de cordura del modelo\n",
    "\n",
    "El dataset (`users_behavior.csv`) contiene la siguiente información para cada usuario:\n",
    "- `calls`: número de llamadas\n",
    "- `minutes`: duración total de llamadas en minutos\n",
    "- `messages`: número de mensajes de texto\n",
    "- `mb_used`: tráfico de Internet utilizado en MB\n",
    "- `is_ultra`: plan del mes actual (Ultra - 1, Smart - 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "importacion-datos",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Cargar el dataset\n",
    "data = pd.read_csv(\"/datasets/users_behavior.csv\")\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "print(\"Primeras filas del dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Mostrar estadísticas descriptivas\n",
    "print(\"Estadísticas descriptivas:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Información general del dataset\n",
    "print(\"Información del dataset:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "division-datos",
   "metadata": {},
   "source": [
    "## División del Conjunto de Datos\n",
    "\n",
    "Separamos las características (`calls`, `minutes`, `messages`, `mb_used`) de la variable objetivo (`is_ultra`) y dividimos el dataset en entrenamiento (60%), validación (20%) y prueba (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características y variable objetivo\n",
    "X = data[['calls', 'minutes', 'messages', 'mb_used']]\n",
    "y = data['is_ultra']\n",
    "\n",
    "# Primera división: entrenamiento (60%) y conjunto temporal (40%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Segunda división: el conjunto temporal se divide en validación (20%) y prueba (20%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", X_train.shape)\n",
    "print(\"Tamaño del conjunto de validación:\", X_val.shape)\n",
    "print(\"Tamaño del conjunto de prueba:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entrenamiento-modelo",
   "metadata": {},
   "source": [
    "## Entrenamiento y Ajuste de Hiperparámetros\n",
    "\n",
    "Utilizaremos un **Random Forest** y `GridSearchCV` para encontrar la mejor combinación de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grid-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el clasificador y la grilla de hiperparámetros\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_rf = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_rf = grid_rf.best_estimator_\n",
    "print(\"Mejores hiperparámetros:\", grid_rf.best_params_)\n",
    "\n",
    "# Evaluar en el conjunto de validación\n",
    "y_val_pred = best_rf.predict(X_val)\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Reporte de clasificación en validación:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluacion-final",
   "metadata": {},
   "source": [
    "## Evaluación Final en el Conjunto de Prueba\n",
    "\n",
    "Una vez seleccionado el mejor modelo basado en el conjunto de validación, se evalúa su desempeño final en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación final en el conjunto de prueba\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "print(\"Accuracy en prueba:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Reporte de clasificación en prueba:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prueba-cordura",
   "metadata": {},
   "source": [
    "## Prueba de Cordura\n",
    "\n",
    "Para verificar que el modelo tiene un comportamiento razonable, examinamos la distribución de las predicciones en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sanity-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la distribución de predicciones\n",
    "unique, counts = np.unique(y_test_pred, return_counts=True)\n",
    "plt.figure()\n",
    "plt.bar(unique, counts)\n",
    "plt.xlabel(\"Clase predicha\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(\"Distribución de predicciones en el conjunto de prueba\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusiones",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En este notebook se ha:\n",
    "\n",
    "- Explorado y analizado el dataset\n",
    "- Dividido los datos en entrenamiento, validación y prueba\n",
    "- Ajustado un modelo de Random Forest mediante GridSearchCV\n",
    "- Evaluado el modelo en conjuntos de validación y prueba\n",
    "    - Se han analizado métricas como la precisión, recall y F1-score\n",
    "- Realizado una prueba de cordura para verificar la distribución de las predicciones\n",
    "\n",
    "Estos pasos permiten obtener un modelo robusto y validar que se comporta de manera coherente con los datos y la problemática planteada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
